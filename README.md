# PyTorch-Proximal-Policy-Optimization-PPO

I finally found a PPO version that can converge from https://github.com/nikhilbarhate99/PPO-PyTorch, I shrink the code a little bit. Parameter action_std controls exploration, which can be set to a small value in testing.
